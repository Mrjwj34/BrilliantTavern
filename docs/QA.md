
---

## BrilliantTavern 规划文档暨议题问题回答

### 1. 目标用户、痛点与用户故事

#### 1.1 目标用户

本项目主要面向以下两类核心用户群体：

1.  **角色扮演爱好者与创作者：** 这部分用户热衷于创造和扮演虚拟角色，享受沉浸式的互动体验。他们可能是小说作者、游戏玩家、或是有丰富想象力并乐于通过角色进行社交的个体。
2.  **寻求情感陪伴与倾诉的个体：** 这部分用户在现实生活中可能感到孤独、缺乏合适的倾诉对象，或因社交焦虑而不愿与真人进行深入交流。他们希望有一个安全、私密且永远“在线”的伙伴来分享想法和感受。

#### 1.2 用户痛点

针对上述用户，我识别出以下核心痛点：

*   **对于角色扮演爱好者：**
    *   **伙伴难寻：** 找到一个能够持续、稳定且高质量地进行角色扮演的伙伴非常困难且耗时。
    *   **时空限制：** 真人伙伴的在线时间不固定，难以随时随地进入扮演状态。
    *   **一致性差：** 真人伙伴可能会忘记设定、偏离角色性格（OOC, Out of Character），破坏沉浸感。
    *   **创作瓶颈：** 将脑海中的角色“活化”出来缺乏有效的工具，单纯的文字描述无法满足他们对角色立体化的需求。

*   **对于寻求情感陪伴者：**
    *   **社交压力：** 与真人交流时会担心被评判、被误解，或需要承担社交责任。
    *   **缺乏安全感：** 很难找到一个能无条件倾听、绝对保密且永远耐心的倾诉对象。
    *   **可得性低：** 在深夜或情绪低落的时刻，往往找不到可以立即交流的人。
    *   **互动单调：** 传统的聊天机器人过于通用和机械，缺乏真实的情感反馈和个性化的记忆。

#### 1.3 用户故事 (User Stories)

基于上述分析，我设想了以下关键的用户故事：

1.  **作为一名角色创作者 (The Creator):**
    *   **我想要** 创建一个包含详细人设、背景故事、性格特点和对话范例的角色卡，
    *   **并且** 为他/她上传或指定一个独特的TTS音色，
    *   **以便于** 将我的原创角色变得栩栩如生，并能与他人或自己进行真实的语音互动。

2.  **作为一名寻求陪伴的用户 (The Companion Seeker):**
    *   **我想要** 在一个感觉安全的私密环境中，与一个我喜欢的、性格温暖的角色进行实时的语音对话，
    *   **以便于** 倾诉我的想法和感受，获得一个不会评判我的虚拟朋友。

3.  **作为一名角色扮演爱好者 (The Role-player):**
    *   **我想要** 浏览一个由社区创建的、丰富多样的角色市场，
    *   **并且** 与那些能够记住我们之间重要对话的角色进行长期、有连续性的互动，
    *   **以便于** 享受高质量、高沉浸感的角色扮演体验。

4.  **作为一名社区参与者 (The Community Member):**
    *   **我想要** 对我喜欢的角色卡和角色音色进行点赞和评论，
    *   **以便于** 表达我的喜爱，支持优秀的创作者，并与其他同好进行交流。

### 2. 功能规划与优先级

基于用户故事和痛点，我将项目功能划分为不同优先级，并明确本次已完成的开发范围。

#### 2.1 功能模块与优先级

| 优先级 | 功能模块 | 核心描述 | 代码实现模块 |
| :--- | :--- | :--- | :--- |
| **P0 (核心)** | **用户认证管理** | 用户注册、登录、JWT身份验证，保障系统安全和用户数据隔离。 | `AuthController`, `AuthService`, `SecurityConfig` |
| **P0 (核心)** | **角色卡管理** | 创建、编辑、查看、删除角色卡。支持公开/私密，搜索、排序和分页。 | `CharacterCardController`, `CharacterCardService` |
| **P0 (核心)** | **实时语音对话** | 基于WebSocket的端到端流式语音聊天，包括语音识别、AI处理、语音合成。 | `VoiceWebSocketController`, `StreamingVoiceOrchestrator`, `AIService`, `TTSManagerService` |
| **P1 (重要)** | **社区互动功能** | 对角色卡进行点赞和评论，支持评论回复、点赞和置顶。 | `CharacterCardService`, `CommentService`, `CommentController` |
| **P1 (重要)** | **音色管理** | 用户可上传参考音频创建个人或公开的TTS音色，并应用于角色卡。 | `TTSVoiceController`, `TTSVoiceService`, `FishSpeechTTSService` |

#### 2.2 本次开发范围

**本次开发已全面完成 P0 和 P1 的所有功能。**

项目已经构建了一个功能完备的核心框架，从用户的加入，到核心内容（角色卡、音色）的创造与分享，再到最关键的实时语音互动体验，以及促进社区活跃度的互动功能，均已实现。这为产品的冷启动和核心用户验证奠定了坚实的基础。

### 3. LLM 模型选型

#### 3.1 选型结论

我决定采用 **Google 的 Gemini 2.5 Flash** 模型作为核心的语言模型能力。

#### 3.2 对比分析

在选型过程中，我对市面上主流的几款模型进行了综合评估，包括 **DeepSeek**, **Qwen**, 和 **Claude 4 Sonnet**。评估维度如下：

| 模型 | 角色扮演能力 | 响应速度 (延迟) | API 定价 | 多模态能力 | 指令遵循/格式化输出 |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **Gemini 2.5 Flash** | **极佳** | **极快** | **极具竞争力** | **原生支持** (音频/图像) | **优秀** |
| DeepSeek-V3.1 | 优秀 | 中等 | 极低 | 不支持 | 良好 |
| Qwen系列 | 一般 | 中等 | 较低 | 支持 | 良好 |
| Claude 4 | 一般 | 快/中等 | 中等 | 支持 | 优秀 |

#### 3.3 选择 Gemini 2.5 Flash 的核心理由

1.  **卓越的角色扮演能力：** 根据我近一年的实际 AI Role-playing 经验对比，Gemini 系列在维持角色人设、捕捉情感细节、进行富有创造力的对话方面表现最佳。它能很好地理解并执行提示词中定义的复杂角色指令，提供极高的沉浸感。

2.  **为语音而生的低延迟：** 作为 `Flash` 模型，其核心优化目标就是速度。对于实时语音对话而言，延迟是决定体验成败的关键。Gemini 2.5 Flash 能够提供极低的“首Token延迟”，确保用户说完话后，AI 能迅速开始生成回复并合成语音，避免了尴尬的沉默。

3.  **强大的原生多模态能力：** 这是我选择 Gemini 的决定性因素就是我可以**直接将用户的原始音频数据 (`byte[]`) 作为输入**发送给 Gemini 模型。模型在一步之内同时完成了**语音识别 (ASR)** 和 **自然语言理解 (NLU)**。
    *   **架构优势：** 这极大地简化了后端架构，我无需再单独集成第三方的 ASR 服务，降低了系统复杂度和潜在的延迟。
    *   **体验优势：** 模型能直接理解音频中的语气、情感等非文本信息，从而做出更人性化的回应。

4.  **优秀的指令遵循与格式化输出：** 我设计的流式处理架构强依赖于 LLM 准确输出 `[TSS]`, `[SUB]`, `[DO]` 等特殊标签。Gemini 在这方面表现稳定，能够可靠地生成结构化响应，驱动后端的异步任务。

5.  **极具竞争力的成本效益：** 在提供顶级性能的同时，Gemini 2.5 Flash 的定价非常有竞争力，这对于需要处理大量实时会话的语音聊天应用来说，是保证项目能长期、可扩展运营的关键。

### 4. AI 角色核心技能

我期望 AI 角色不仅仅是一个聊天伙伴，更是一个具备多种能力的智能体。除了基础的语音聊天，在本次开发中，我为 AI 角色实现了以下高级技能：

1.  **全局记忆与情景感知 (基于RAG)：**
    *   **技能描述：** 角色能够“记住”在对话中被明确告知需要记忆的关键信息，并在后续的对话中主动或被动地回忆起这些信息，实现跨会话的记忆连续性。
    *   **实现方式：**
        *   **记忆存储：** AI 模型被训练成在需要时输出 `[DO]remember("需要记住的内容")` 指令。后端的 `MethodExecutionHandler` 捕获此指令，调用 `CharacterMemoryService` 将文本内容生成向量（`vector(1536)`），并存入 `character_memories` 数据库表。
        *   **记忆检索：** 当对话需要时，AI 模型会输出 `[MEM]我想回忆一下关于...的事情[/MEM]`。后端的 `AIService` 捕获此模式，将查询文本向量化后在数据库中进行向量相似度搜索，找到最相关的记忆。这些记忆会被动态地注入到当前的对话上下文中，帮助 AI 做出更具情景感知的回应。

2.  **动态图像生成 (文生图)：**
    *   **技能描述：** 角色可以根据对话内容，动态生成图片。这可以是描绘场景的插图，也可以是角色的“自画像”。
    *   **实现方式：**
        *   **技能触发：** AI 模型通过输出 `[DO]imagen(isSelf, "图片描述")` 指令来触发。`isSelf` 参数决定了是生成自画像还是普通场景。
        *   **图像生成：** `MethodExecutionHandler` 调用 `ImageGenerationService`，该服务使用 Gemini 的图像生成能力 (`gemini-2.5-flash-image-preview`) 来创建图片。特别地，在生成自画像时，如果角色卡设置了头像，该头像会被用作参考图，以保证生成图像的风格和角色形象的一致性。
        *   **结果反馈：** 生成的图片链接会通过 `METHOD_EXECUTION` WebSocket 事件返回给前端展示，并记录在聊天历史中。

3.  **复杂的指令遵循与工具使用 (Tool Use)：**
    *   **技能描述：** 这是上述所有技能的基础。AI 角色不仅仅是在生成文本，而是在生成一个包含多项任务的“执行计划”。
    *   **实现方式：** 通过我设计的标签系统，AI 的一次回复可以被解析为多个并行的任务流：
        *   `[TSS:zh]...[/TSS]`: 这部分文本将被发送到 TTS 服务进行语音合成。
        *   `[SUB:zh]...[/SUB]`: 这部分文本将作为字幕流式推送到前端。
        *   `[DO]...[/DO]`: 这部分内容是需要后端执行的函数调用，如 `remember(...)` 或 `imagen(...)`。
    后端的 `StreamingContentParser` 和 `AsyncEventDispatcher` 协同工作，实时解析这些指令并分发给对应的处理器并行执行，实现了文本、语音、方法调用同步进行的复杂交互。